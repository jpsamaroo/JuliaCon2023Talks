{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22900fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/docs/JuliaCon/2023/HPC`\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling Dagger [d58978e5-989f-55fb-8d15-ea34adc7bf54]\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mPrecompiling DaggerGPU [68e73e28-2238-4d5a-bf97-e5d4aa3c4be2]\n"
     ]
    }
   ],
   "source": [
    "include(\"setup.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443ad15",
   "metadata": {},
   "source": [
    "![](https://github.com/JuliaParallel/Dagger.jl/raw/master/docs/logo.jpg)\n",
    "\n",
    "## Dagger for HPC\n",
    "\n",
    "#### Written by: Julian Samaroo, Research Software Engineer at MIT's JuliaLab, maintainer of Dagger.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d50225",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Dagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da3314d",
   "metadata": {},
   "source": [
    "## What is Dagger?\n",
    "- A Julia library that makes parallel programming portable, performant, and productive\n",
    "- Unifies Julia's multithreading, multiprocessing (distributed), and GPU computing capabilities\n",
    "- Easy to write code on a laptop and deploy it at scale (supercomputer, cloud, etc.)\n",
    "\n",
    "### Ecosystem problems:\n",
    "1. Multithreading, distributed, and GPU computing don't compose\n",
    "2. Efficient task scheduling and data movement is hard to do manually\n",
    "3. N-to-M problem of abstractions to parallelism strategies\n",
    "4. Different end-user hardware configurations\n",
    "\n",
    "### Dagger's solutions:\n",
    "1. Unified task and data movement concepts\n",
    "2. Heterogeneous scheduler using machine learning\n",
    "3. High-level APIs all call the same task API underneath\n",
    "4. Hardware awareness and flexible processor abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d861fcca",
   "metadata": {},
   "source": [
    "## Enough talk! This is JuliaCon, show me the code!\n",
    "\n",
    "### Distributed Arrays\n",
    "\n",
    "Let's look at all of Dagger's various interfaces, starting with the distributed array interface, the `DArray`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fb07dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64×64 Matrix{Float64}:\n",
       " 1.42442   1.75499     0.512983  …  1.54363   0.10699   1.74991\n",
       " 0.187488  1.04904     0.535902     0.991907  1.95852   1.46149\n",
       " 0.504441  0.608903    1.24177      0.369546  1.86473   0.610309\n",
       " 0.425605  0.308427    0.551054     0.604314  1.58523   0.819905\n",
       " 1.56785   0.943423    1.23804      0.272528  0.921236  1.59822\n",
       " 1.29823   1.31296     1.92522   …  0.497407  0.372783  0.309022\n",
       " 0.121636  0.525815    0.345753     0.304693  1.63458   0.844098\n",
       " 0.631788  1.41564     0.772955     1.40852   0.672284  0.0138266\n",
       " 0.253049  1.78613     0.579613     0.930276  1.31191   0.141314\n",
       " 0.444186  1.26853     1.59303      0.96387   1.40387   0.399772\n",
       " 1.97589   0.675521    0.726675  …  0.724015  1.67095   1.86371\n",
       " 0.129561  0.085523    1.292        0.94088   1.56437   1.79553\n",
       " 0.496854  1.14083     1.15055      1.71245   1.67252   0.400495\n",
       " ⋮                               ⋱                      \n",
       " 0.318141  1.2417      1.86648      1.73593   0.688311  0.30338\n",
       " 0.543354  0.382135    1.25994      0.555401  1.30041   0.00996781\n",
       " 1.41656   0.560443    0.078872     1.74953   0.947042  0.999674\n",
       " 1.04058   1.19812     1.28375   …  1.55906   0.196252  1.53219\n",
       " 0.645218  0.787987    1.20599      1.87174   0.466419  1.19967\n",
       " 0.403981  1.62402     1.17451      0.57525   1.32053   1.52008\n",
       " 1.63226   0.00207121  1.66722      1.08304   0.756352  0.908403\n",
       " 1.58982   0.124123    1.42317      0.112224  1.3836    0.0869197\n",
       " 0.618107  1.81747     1.43759   …  1.72322   1.17548   1.13847\n",
       " 1.57644   1.3022      1.29207      1.59985   1.62507   0.262664\n",
       " 0.618325  0.848314    1.81673      0.922896  0.192492  1.65652\n",
       " 0.757996  1.12473     0.337432     0.88547   1.05646   1.33267"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(64, 64)\n",
    "\n",
    "# Let's distribute A across our workers by partitioning in 16 x 16 blocks\n",
    "DA = distribute(A, Blocks(16, 16))\n",
    "\n",
    "# Do an operation on it:\n",
    "DB = map(x->x*2, DA)\n",
    "\n",
    "# And get the result back as an Array:\n",
    "collect(DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7a6667c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64×64 Matrix{Float64}:\n",
       " 0.658126   0.283695   0.796985   …  0.749473  0.811277   0.0527573\n",
       " 0.203491   0.294815   0.581946      0.209931  0.952948   0.34408\n",
       " 0.604561   0.334882   0.787896      0.500641  0.969723   0.746681\n",
       " 0.198857   0.670821   0.128755      0.856966  0.644631   0.251717\n",
       " 0.603761   0.0260362  0.939373      0.832957  0.39569    0.530448\n",
       " 0.566787   0.663621   0.642383   …  0.958785  0.943038   0.918318\n",
       " 0.31308    0.331933   0.319969      0.44801   0.30823    0.446051\n",
       " 0.0946     0.364543   0.58955       0.470084  0.289969   0.916626\n",
       " 0.833488   0.610157   0.530583      0.731231  0.598206   0.274763\n",
       " 0.931132   0.633184   0.448787      0.969361  0.590173   0.705504\n",
       " 0.869467   0.104607   0.652301   …  0.652722  0.418679   0.396207\n",
       " 0.858183   0.488585   0.934774      0.252574  0.755862   0.371537\n",
       " 0.0574044  0.705903   0.0725693     0.60596   0.0762379  0.545298\n",
       " ⋮                                ⋱                       \n",
       " 0.431993   0.844963   0.257325      0.824322  0.812598   0.398477\n",
       " 0.473049   0.10608    0.0807926     0.801811  0.79724    0.79189\n",
       " 0.97333    0.164201   0.0535385     0.078505  0.251787   0.572893\n",
       " 0.0671267  0.945947   0.751004   …  0.588771  0.0125128  0.951788\n",
       " 0.459433   0.680404   0.507375      0.870027  0.702105   0.217252\n",
       " 0.558258   0.908584   0.559697      0.165858  0.670083   0.249841\n",
       " 0.643866   0.0672863  0.0384516     0.251403  0.827731   0.922702\n",
       " 0.0188698  0.316189   0.238387      0.273253  0.848983   0.623865\n",
       " 0.333603   0.82129    0.977454   …  0.171733  0.651598   0.413531\n",
       " 0.775529   0.869791   0.734007      0.184206  0.600685   0.630684\n",
       " 0.914089   0.334895   0.996914      0.922566  0.23225    0.990873\n",
       " 0.791793   0.3058     0.383884      0.282872  0.827435   0.180136"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or allocate an array directly:\n",
    "collect(rand(Blocks(16, 16), 64, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94f22c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(DA) = 2031.5587026509343\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64×64 Matrix{Float64}:\n",
       " 2.84885   3.50999     1.02597   3.34773    …  3.08727   0.213979  3.49983\n",
       " 0.374976  2.09808     1.0718    0.578355      1.98381   3.91705   2.92298\n",
       " 1.00888   1.21781     2.48354   1.06243       0.739091  3.72946   1.22062\n",
       " 0.85121   0.616854    1.10211   1.22413       1.20863   3.17046   1.63981\n",
       " 3.1357    1.88685     2.47609   0.225156      0.545056  1.84247   3.19644\n",
       " 2.59647   2.62592     3.85044   3.95635    …  0.994813  0.745566  0.618044\n",
       " 0.243271  1.05163     0.691505  3.28188       0.609386  3.26917   1.6882\n",
       " 1.26358   2.83128     1.54591   2.02111       2.81703   1.34457   0.0276533\n",
       " 0.506098  3.57226     1.15923   0.668858      1.86055   2.62382   0.282628\n",
       " 0.888372  2.53705     3.18606   3.48046       1.92774   2.80775   0.799543\n",
       " 3.95178   1.35104     1.45335   3.72815    …  1.44803   3.34189   3.72742\n",
       " 0.259122  0.171046    2.584     2.61396       1.88176   3.12874   3.59105\n",
       " 0.993709  2.28166     2.30109   3.6471        3.4249    3.34505   0.800991\n",
       " ⋮                                          ⋱                      \n",
       " 0.636281  2.48339     3.73297   1.87767       3.47186   1.37662   0.606761\n",
       " 1.08671   0.76427     2.51988   1.02511       1.1108    2.60082   0.0199356\n",
       " 2.83313   1.12089     0.157744  3.72667       3.49906   1.89408   1.99935\n",
       " 2.08116   2.39624     2.5675    0.0382216  …  3.11812   0.392505  3.06438\n",
       " 1.29044   1.57597     2.41199   2.16982       3.74348   0.932837  2.39934\n",
       " 0.807961  3.24804     2.34902   3.94161       1.1505    2.64106   3.04016\n",
       " 3.26452   0.00414241  3.33444   2.34804       2.16608   1.5127    1.81681\n",
       " 3.17964   0.248245    2.84634   2.80764       0.224447  2.7672    0.173839\n",
       " 1.23621   3.63494     2.87519   2.44092    …  3.44643   2.35096   2.27695\n",
       " 3.15288   2.6044      2.58414   0.0176451     3.19971   3.25014   0.525328\n",
       " 1.23665   1.69663     3.63345   3.10581       1.84579   0.384984  3.31304\n",
       " 1.51599   2.24947     0.674864  2.72959       1.77094   2.11292   2.66533"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reductions and broadcast work too!\n",
    "@show sum(DA)\n",
    "collect(DA .* 2 .+ DB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1481fa51",
   "metadata": {},
   "source": [
    "Where's the proof that it's distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb5c33d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64×64 Matrix{Int64}:\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2  …  3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2  …  3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2  …  3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     3  3  3  3  3  3  3  3  3  3  3  3\n",
       " ⋮              ⋮              ⋮        ⋱           ⋮              ⋮        \n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3  …  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3  …  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 3  3  3  3  3  3  3  3  3  3  3  3  3     1  1  1  1  1  1  1  1  1  1  1  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can easily see which worker we're running on:\n",
    "collect(map(x->Distributed.myid(), DB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9fe63a",
   "metadata": {},
   "source": [
    "Dagger also automates multithreading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "287eca8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64×64 Matrix{Int64}:\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2  …  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2  …  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2  …  1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " 2  2  2  2  2  2  2  2  2  2  2  2  2     1  1  1  1  1  1  1  1  1  1  1  1\n",
       " ⋮              ⋮              ⋮        ⋱           ⋮              ⋮        \n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4  …  6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4  …  6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6\n",
       " 4  4  4  4  4  4  4  4  4  4  4  4  4     6  6  6  6  6  6  6  6  6  6  6  6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And we can check which thread we're on too:\n",
    "collect(map(x->Threads.threadid(), DB))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d646794d",
   "metadata": {},
   "source": [
    "#### Supercomputer parallelism: MPI\n",
    "\n",
    "Amazingly, thanks to our Google Summer of Code student Felipe Tome, the `DArray` also supports MPI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd913ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We won't run this because we aren't running under MPI\n",
    "# Try it on your favorite supercomputer :)\n",
    "\n",
    "using DaggerMPI, MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "nranks = MPI.Comm_size(comm)\n",
    "\n",
    "# Automatically partition array across MPI ranks\n",
    "DA = rand(MPIBlocks(64, nothing), 64, 64)\n",
    "# Same here!\n",
    "DB = distribute(rand(64, 64), MPIBlocks(64, nothing))\n",
    "\n",
    "# Array operations work fine\n",
    "# (They also automatically use MPI!)\n",
    "DC = map(x->x+1, DA)\n",
    "DD = DB .+ DC\n",
    "collect(DD) # Exactly what you'd expect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1ec1f0",
   "metadata": {},
   "source": [
    "### Distributed Tables\n",
    "\n",
    "Let's see other abstractions; the DTables.jl package exposes distributed tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79a3f745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DTable with 5 partitions\n",
       "Tabletype: DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DTables, DataFrames\n",
    "\n",
    "df = DataFrame(a=rand(1:100), b=rand('a':'z', 100))\n",
    "dtbl = DTable(df, 20) # Partition into sub-tables of 20 rows each"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb00419",
   "metadata": {},
   "source": [
    "Like the `DArray`, the `DTable` is split into partitions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4a6e64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch(dtbl.chunks[2]) = 20×2 DataFrame\n",
      " Row │ a      b\n",
      "     │ Int64  Char\n",
      "─────┼─────────────\n",
      "   1 │    94  y\n",
      "   2 │    94  u\n",
      "   3 │    94  h\n",
      "   4 │    94  w\n",
      "   5 │    94  b\n",
      "   6 │    94  x\n",
      "   7 │    94  a\n",
      "   8 │    94  h\n",
      "   9 │    94  e\n",
      "  10 │    94  o\n",
      "  11 │    94  v\n",
      "  12 │    94  v\n",
      "  13 │    94  q\n",
      "  14 │    94  y\n",
      "  15 │    94  b\n",
      "  16 │    94  u\n",
      "  17 │    94  r\n",
      "  18 │    94  r\n",
      "  19 │    94  g\n",
      "  20 │    94  k\n",
      "fetch(dtbl.chunks[4]) = 20×2 DataFrame\n",
      " Row │ a      b\n",
      "     │ Int64  Char\n",
      "─────┼─────────────\n",
      "   1 │    94  o\n",
      "   2 │    94  x\n",
      "   3 │    94  o\n",
      "   4 │    94  l\n",
      "   5 │    94  x\n",
      "   6 │    94  r\n",
      "   7 │    94  j\n",
      "   8 │    94  q\n",
      "   9 │    94  u\n",
      "  10 │    94  c\n",
      "  11 │    94  r\n",
      "  12 │    94  l\n",
      "  13 │    94  m\n",
      "  14 │    94  q\n",
      "  15 │    94  j\n",
      "  16 │    94  k\n",
      "  17 │    94  j\n",
      "  18 │    94  n\n",
      "  19 │    94  j\n",
      "  20 │    94  m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>20×2 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">a</th><th style = \"text-align: left;\">b</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Char\" style = \"text-align: left;\">Char</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">o</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">x</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">o</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">l</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">x</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">r</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">j</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">q</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">u</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">c</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">r</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">l</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">m</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">14</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">q</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">15</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">j</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">16</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">k</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">17</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">j</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">18</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">n</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">19</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">j</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">20</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">m</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cc}\n",
       "\t& a & b\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Char\\\\\n",
       "\t\\hline\n",
       "\t1 & 94 & o \\\\\n",
       "\t2 & 94 & x \\\\\n",
       "\t3 & 94 & o \\\\\n",
       "\t4 & 94 & l \\\\\n",
       "\t5 & 94 & x \\\\\n",
       "\t6 & 94 & r \\\\\n",
       "\t7 & 94 & j \\\\\n",
       "\t8 & 94 & q \\\\\n",
       "\t9 & 94 & u \\\\\n",
       "\t10 & 94 & c \\\\\n",
       "\t11 & 94 & r \\\\\n",
       "\t12 & 94 & l \\\\\n",
       "\t13 & 94 & m \\\\\n",
       "\t14 & 94 & q \\\\\n",
       "\t15 & 94 & j \\\\\n",
       "\t16 & 94 & k \\\\\n",
       "\t17 & 94 & j \\\\\n",
       "\t18 & 94 & n \\\\\n",
       "\t19 & 94 & j \\\\\n",
       "\t20 & 94 & m \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m20×2 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m a     \u001b[0m\u001b[1m b    \u001b[0m\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Char \u001b[0m\n",
       "─────┼─────────────\n",
       "   1 │    94  o\n",
       "   2 │    94  x\n",
       "   3 │    94  o\n",
       "   4 │    94  l\n",
       "   5 │    94  x\n",
       "   6 │    94  r\n",
       "   7 │    94  j\n",
       "   8 │    94  q\n",
       "   9 │    94  u\n",
       "  10 │    94  c\n",
       "  11 │    94  r\n",
       "  12 │    94  l\n",
       "  13 │    94  m\n",
       "  14 │    94  q\n",
       "  15 │    94  j\n",
       "  16 │    94  k\n",
       "  17 │    94  j\n",
       "  18 │    94  n\n",
       "  19 │    94  j\n",
       "  20 │    94  m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show fetch(dtbl.chunks[2]) fetch(dtbl.chunks[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f02e004",
   "metadata": {},
   "source": [
    "And it's quite easy to show that operations are distributed+multithreaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb839382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>100×4 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">75 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">a</th><th style = \"text-align: left;\">b</th><th style = \"text-align: left;\">wid</th><th style = \"text-align: left;\">tid</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Char\" style = \"text-align: left;\">Char</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">y</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">w</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">f</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">h</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">y</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">w</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">j</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">m</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">l</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">q</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">f</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">c</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">l</td><td style = \"text-align: right;\">3</td><td style = \"text-align: right;\">2</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">89</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">y</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">90</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">b</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">91</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">w</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">92</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">m</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">93</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">h</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">94</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">l</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">95</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">w</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">96</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">r</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">97</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">t</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">98</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">f</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">99</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">z</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">100</td><td style = \"text-align: right;\">94</td><td style = \"text-align: left;\">c</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& a & b & wid & tid\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Char & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 94 & y & 3 & 2 \\\\\n",
       "\t2 & 94 & w & 3 & 2 \\\\\n",
       "\t3 & 94 & f & 3 & 2 \\\\\n",
       "\t4 & 94 & h & 3 & 2 \\\\\n",
       "\t5 & 94 & y & 3 & 2 \\\\\n",
       "\t6 & 94 & w & 3 & 2 \\\\\n",
       "\t7 & 94 & j & 3 & 2 \\\\\n",
       "\t8 & 94 & m & 3 & 2 \\\\\n",
       "\t9 & 94 & l & 3 & 2 \\\\\n",
       "\t10 & 94 & q & 3 & 2 \\\\\n",
       "\t11 & 94 & f & 3 & 2 \\\\\n",
       "\t12 & 94 & c & 3 & 2 \\\\\n",
       "\t13 & 94 & l & 3 & 2 \\\\\n",
       "\t14 & 94 & b & 3 & 2 \\\\\n",
       "\t15 & 94 & o & 3 & 2 \\\\\n",
       "\t16 & 94 & g & 3 & 2 \\\\\n",
       "\t17 & 94 & u & 3 & 2 \\\\\n",
       "\t18 & 94 & y & 3 & 2 \\\\\n",
       "\t19 & 94 & h & 3 & 2 \\\\\n",
       "\t20 & 94 & z & 3 & 2 \\\\\n",
       "\t21 & 94 & y & 1 & 6 \\\\\n",
       "\t22 & 94 & u & 1 & 6 \\\\\n",
       "\t23 & 94 & h & 1 & 6 \\\\\n",
       "\t24 & 94 & w & 1 & 6 \\\\\n",
       "\t25 & 94 & b & 1 & 6 \\\\\n",
       "\t26 & 94 & x & 1 & 6 \\\\\n",
       "\t27 & 94 & a & 1 & 6 \\\\\n",
       "\t28 & 94 & h & 1 & 6 \\\\\n",
       "\t29 & 94 & e & 1 & 6 \\\\\n",
       "\t30 & 94 & o & 1 & 6 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m100×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m a     \u001b[0m\u001b[1m b    \u001b[0m\u001b[1m wid   \u001b[0m\u001b[1m tid   \u001b[0m\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m Char \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "─────┼───────────────────────────\n",
       "   1 │    94  y         3      2\n",
       "   2 │    94  w         3      2\n",
       "   3 │    94  f         3      2\n",
       "   4 │    94  h         3      2\n",
       "   5 │    94  y         3      2\n",
       "   6 │    94  w         3      2\n",
       "   7 │    94  j         3      2\n",
       "   8 │    94  m         3      2\n",
       "   9 │    94  l         3      2\n",
       "  10 │    94  q         3      2\n",
       "  11 │    94  f         3      2\n",
       "  ⋮  │   ⋮     ⋮      ⋮      ⋮\n",
       "  91 │    94  w         1      5\n",
       "  92 │    94  m         1      5\n",
       "  93 │    94  h         1      5\n",
       "  94 │    94  l         1      5\n",
       "  95 │    94  w         1      5\n",
       "  96 │    94  r         1      5\n",
       "  97 │    94  t         1      5\n",
       "  98 │    94  f         1      5\n",
       "  99 │    94  z         1      5\n",
       " 100 │    94  c         1      5\n",
       "\u001b[36m                  79 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(row->merge(row, (;wid=Distributed.myid(), tid=Threads.threadid())), dtbl) |> DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5185b7",
   "metadata": {},
   "source": [
    "#### How do these abstractions work?\n",
    "\n",
    "- All computations done in Dagger tasks\n",
    "- All data stored in Dagger `Chunk`s\n",
    "- Single unified scheduler handles all the details\n",
    "\n",
    "This gives us free features like distributed+multithreaded computing, out-of-core computing, and more!\n",
    "\n",
    "### Distributed Loops and Transducers\n",
    "\n",
    "These simple core features also make it easy to build other abstractions, like accelerated loops and transducers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eacd5893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(collect(DC))[1:4] = [0.6700156037773604, 0.8285620101463849, 0.43402200373501265, 0.9041125621838035]\n",
      "(collect(DC))[1:4] = [42.67001560377736, 42.828562010146385, 42.43402200373501, 42.904112562183805]\n"
     ]
    }
   ],
   "source": [
    "using FoldsDagger, FLoops, Referenceables\n",
    "\n",
    "# Note: We're locking this array and computations to worker 1\n",
    "# because of some unresolved distributed issues with FoldsDagger\n",
    "Dagger.with_options(;scope=Dagger.scope(worker=1)) do\n",
    "    DC = rand(Blocks(4), 16)\n",
    "\n",
    "    @show collect(DC)[1:4]\n",
    "\n",
    "    @floop DaggerEx() for x in referenceable(DC)\n",
    "        x[] += 42.0\n",
    "    end\n",
    "\n",
    "    @show collect(DC)[1:4]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "992e9a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(DC) = 7.603597375606933\n",
      "sum(collect(DC)) = 7.603597375606933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFailed with CartesianIndex(1,) 1 1\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching getindex(::CartesianIndex{1}, ::UnitRange{Int64})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  getindex(::CartesianIndex, \u001b[91m::Integer\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmultidimensional.jl:90\u001b[24m\u001b[39m\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching getindex(::CartesianIndex{1}, ::UnitRange{Int64})\n\n\u001b[0mClosest candidates are:\n\u001b[0m  getindex(::CartesianIndex, \u001b[91m::Integer\u001b[39m)\n\u001b[0m\u001b[90m   @\u001b[39m \u001b[90mBase\u001b[39m \u001b[90m\u001b[4mmultidimensional.jl:90\u001b[24m\u001b[39m\n",
      "",
      "Stacktrace:",
      "  [1] group_indices(cumlength::Vector{Int64}, idxs::CartesianIndex{1}, at::Int64, acc::Vector{Any})",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/array/darray.jl:238",
      "  [2] group_indices(cumlength::Vector{Int64}, idxs::CartesianIndex{1})",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/array/darray.jl:223",
      "  [3] map",
      "    @ ./tuple.jl:0 [inlined]",
      "  [4] lookup_parts(ps::Vector{Any}, subdmns::Dagger.DomainBlocks{1}, d::ArrayDomain{1})",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/array/darray.jl:261",
      "  [5] view(c::Dagger.DArray{Float64, 1, Blocks{1}, typeof(cat)}, d::ArrayDomain{1})",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/array/darray.jl:217",
      "  [6] stage(ctx::Context, gidx::Dagger.GetIndex{Float64, 1})",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/array/getindex.jl:20",
      "  [7] cached_stage(ctx::Context, x::Dagger.GetIndex{Float64, 1})",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/array/darray.jl:322",
      "  [8] _to_darray(x::Dagger.GetIndex{Float64, 1})",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/array/darray.jl:83",
      "  [9] getindex",
      "    @ ~/.julia/dev/Dagger-tags/src/array/getindex.jl:41 [inlined]",
      " [10] getvalue",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:223 [inlined]",
      " [11] next (repeats 2 times)",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/library.jl:54 [inlined]",
      " [12] macro expansion",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/core.jl:181 [inlined]",
      " [13] macro expansion",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:323 [inlined]",
      " [14] macro expansion",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/simd.jl:41 [inlined]",
      " [15] _foldl_product",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:322 [inlined]",
      " [16] __foldl__",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:293 [inlined]",
      " [17] _foldl_array",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:225 [inlined]",
      " [18] __foldl__",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:182 [inlined]",
      " [19] #transduce#142",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:519 [inlined]",
      " [20] transduce",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:508 [inlined]",
      " [21] #transduce#141",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:502 [inlined]",
      " [22] transduce",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:500 [inlined]",
      " [23] _collect",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:806 [inlined]",
      " [24] collect",
      "    @ ~/.julia/packages/Transducers/xbs8O/src/processes.jl:802 [inlined]",
      " [25] collect(foldable::Transducers.Eduction{Transducers.Reduction{Filter{var\"#16#18\"}, Transducers.BottomRF{Completing{typeof(push!!)}}}, Dagger.DArray{Float64, 1, Blocks{1}, typeof(cat)}})",
      "    @ Transducers ~/.julia/packages/Transducers/xbs8O/src/processes.jl:803",
      " [26] macro expansion",
      "    @ ./show.jl:1128 [inlined]",
      " [27] (::var\"#15#17\")()",
      "    @ Main ./In[5]:11",
      " [28] (::Dagger.var\"#21#22\"{var\"#15#17\"})()",
      "    @ Dagger ~/.julia/dev/Dagger-tags/src/options.jl:17",
      " [29] with_logstate(f::Function, logstate::Any)",
      "    @ Base.CoreLogging ./logging.jl:514",
      " [30] with_logger",
      "    @ ./logging.jl:626 [inlined]",
      " [31] with_task_ctxvars(f::Any, ctx::Any)",
      "    @ ContextVariablesX ~/.julia/packages/ContextVariablesX/ujYRr/src/payloadlogger.jl:16",
      " [32] with_context(f::Function, kvs::Pair{ContextVariablesX.ContextVar{NamedTuple}, NamedTuple{(:scope,), Tuple{ProcessScope}}})",
      "    @ ContextVariablesX ~/.julia/packages/ContextVariablesX/ujYRr/src/ContextVariablesX.jl:336",
      " [33] with_options",
      "    @ ~/.julia/dev/Dagger-tags/src/options.jl:16 [inlined]",
      " [34] #with_options#23",
      "    @ ~/.julia/dev/Dagger-tags/src/options.jl:20 [inlined]",
      " [35] top-level scope",
      "    @ In[5]:3"
     ]
    }
   ],
   "source": [
    "using Folds, Transducers\n",
    "\n",
    "Dagger.with_options(;scope=Dagger.scope(worker=1)) do\n",
    "    DC = rand(Blocks(4), 16)\n",
    "\n",
    "    #@show Folds.sum(DC)\n",
    "    # For comparison:\n",
    "    @show sum(DC) sum(collect(DC))\n",
    "    \n",
    "    DD = DC |> Filter(x->x < 0.5)\n",
    "    @show collect(DD)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e777b0e",
   "metadata": {},
   "source": [
    "### Distributed SPMD Kernels\n",
    "\n",
    "With DaggerGPU and KernelAbstractions, executing SPMD kernels is super easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2e7f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DaggerGPU, KernelAbstractions\n",
    "import DaggerGPU: Kernel\n",
    "\n",
    "@kernel function vinc!(O, A)\n",
    "    idx = @index(Global, Linear)\n",
    "    O[idx] = A[idx] + 1\n",
    "end\n",
    "\n",
    "@kernel function vadd!(C, A, B)\n",
    "    idx = @index(Global, Linear)\n",
    "    C[idx] = A[idx] + B[idx]\n",
    "end\n",
    "\n",
    "# Start with CPU arrays, locked to this worker\n",
    "A = Dagger.@mutable rand(Float32, 64)\n",
    "O = Dagger.@mutable zeros(Float32, 64)\n",
    "\n",
    "# Launch the kernel in a task and wait for it to finish\n",
    "wait(Dagger.@spawn Kernel(vinc!)(O, A))\n",
    "\n",
    "fetch(O) == fetch(A) .+ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6218e3",
   "metadata": {},
   "source": [
    "This worked! But it only used the CPU - boring! Thankfully, GPU acceleration is trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd3d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using AMDGPU\n",
    "\n",
    "# This time we use AMDGPU's ROCArrays\n",
    "A = Dagger.@mutable AMDGPU.rand(Float32, 64)\n",
    "O = Dagger.@mutable AMDGPU.zeros(Float32, 64)\n",
    "\n",
    "# Specify a \"scope\" of execution on only the first ROCm (AMD) GPU\n",
    "gpu_scope = Dagger.scope(rocm_gpu=1)\n",
    "\n",
    "# or, for using any GPU, do:\n",
    "# gpu_scope = Dagger.ProcessorTypeScope(DaggerGPU.ROCArrayDeviceProc)\n",
    "# (This will become easier to specify in the future!)\n",
    "\n",
    "# Launch the kernel on the first AMD GPU\n",
    "Dagger.with_options(;scope=gpu_scope) do\n",
    "    wait(Dagger.@spawn Kernel(vinc!)(O, A))\n",
    "end\n",
    "\n",
    "fetch(O) == fetch(A) .+ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea60f439",
   "metadata": {},
   "source": [
    "Ok, that's fine, but this is only one kernel; what if I need to launch a bunch in sequence? No problem - `spawn_sequential` to the rescue!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61449a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = Dagger.@mutable AMDGPU.rand(Float32, 64)\n",
    "B = Dagger.@mutable AMDGPU.rand(Float32, 64)\n",
    "C = Dagger.@mutable AMDGPU.zeros(Float32, 64)\n",
    "O = Dagger.@mutable AMDGPU.zeros(Float32, 64)\n",
    "\n",
    "# Launch two kernels in sequential order\n",
    "Dagger.with_options(;scope=gpu_scope) do\n",
    "    wait(Dagger.spawn_sequential() do\n",
    "        Dagger.@spawn Kernel(vadd!)(C, A, B)\n",
    "        Dagger.@spawn Kernel(vinc!)(O, C)\n",
    "    end)\n",
    "end\n",
    "\n",
    "fetch(O) == fetch(A) .+ fetch(B) .+ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc9de40",
   "metadata": {},
   "source": [
    "Above, even though Dagger normally only orders by function arguments (requiring annoying tricks to make work), `spawn_sequential` forced sequential task ordering for each submitted task.\n",
    "\n",
    "What about if I need parallel kernels? No problem, just use `spawn_bulk` within:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432e56e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z1 = Dagger.@mutable AMDGPU.rand(Float32, 64)\n",
    "Z2 = Dagger.@mutable AMDGPU.rand(Float32, 64)\n",
    "A = Dagger.@mutable AMDGPU.zeros(Float32, 64)\n",
    "B = Dagger.@mutable AMDGPU.zeros(Float32, 64)\n",
    "C = Dagger.@mutable AMDGPU.zeros(Float32, 64)\n",
    "\n",
    "Dagger.with_options(;scope=gpu_scope) do\n",
    "    wait(Dagger.spawn_sequential() do\n",
    "        # Launch two kernels in parallel\n",
    "        Dagger.spawn_bulk() do\n",
    "            Dagger.@spawn Kernel(vinc!)(A, Z1)\n",
    "            Dagger.@spawn Kernel(vinc!)(B, Z2)\n",
    "        end\n",
    "\n",
    "        # Once those are done, run this kernel\n",
    "        Dagger.@spawn Kernel(vadd!)(C, A, B)\n",
    "    end)\n",
    "end\n",
    "\n",
    "fetch(C) == fetch(Z1) .+ 1 .+ fetch(Z2) .+ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72995d8a",
   "metadata": {},
   "source": [
    "Cool - `spawn_bulk` let us get some controlled parallelism even when we were in a sequential region!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53306fbc",
   "metadata": {},
   "source": [
    "### GPU Array Programming\n",
    "\n",
    "Kernels aren't the only option for GPUs - array programming works just fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f601480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a CPU array (this time, not locked to a worker)...\n",
    "A = rand(Float32, 64)\n",
    "\n",
    "# ... and do some array ops, but all on the GPU!\n",
    "C = Dagger.with_options(;scope=gpu_scope) do\n",
    "    # No need to manually convert to a ROCArray\n",
    "    # Dagger converts and moves data for you\n",
    "    B = Dagger.@spawn A .+ 3\n",
    "    Dagger.@spawn map(x->x/2, B)\n",
    "end\n",
    "\n",
    "# Let's finish with reducing on the CPU\n",
    "# Again, no need to convert manually!\n",
    "fetch(Dagger.@spawn sum(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a97200",
   "metadata": {},
   "source": [
    "### In summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f189db",
   "metadata": {},
   "source": [
    "#### Key Points\n",
    "\n",
    "- Many computational abstractions (array, table, task, kernel)\n",
    "- Integrates with key ecosystem packages (MPI.jl, KernelAbstractions.jl, CUDA/AMDGPU/etc.)\n",
    "- Parallelism is automatic\n",
    "- Change parallelism strategy from top level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a0d13",
   "metadata": {},
   "source": [
    "#### More work to be done (help wanted!)\n",
    "\n",
    "- DArray + KernelAbstractions integration\n",
    "- Distributed graphs implementation (social networks, security research, etc.)\n",
    "- Intel GPU, GraphCore IPU, etc. support in DaggerGPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5100f2f1",
   "metadata": {},
   "source": [
    "#### What can you do?\n",
    "\n",
    "- Use Dagger to solve your computational problems\n",
    "- Report any bugs or performance issues\n",
    "- Add documentation and examples\n",
    "- Add integrations between Dagger and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81107e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
